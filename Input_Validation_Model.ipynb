{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdSKMIbb5sWbHeXr7T0Wzd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zaviruuu/Naga--ML-Based-Snake-Identifier-for-Sri-Lanka-/blob/input_validation_model/Input_Validation_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Input Validation Model\n"
      ],
      "metadata": {
        "id": "6UYLjN85rhVo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Di6NJ0bZrcXM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c17eeb7a-ab98-4a07-efa1-aea0a6411007"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "TensorFlow: 2.19.0\n"
          ]
        }
      ],
      "source": [
        "import os, shutil, random\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "print(\"TensorFlow:\", tf.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIR  = \"/content/drive/MyDrive/DSGP_Group_32/NĀGA/Input Validation Model/Dataset\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/DSGP_Group_32/NĀGA/Input Validation Model/Output\"\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH = 32\n",
        "SEED = 42\n",
        "\n",
        "print(\"INPUT exists :\", os.path.exists(INPUT_DIR))\n",
        "print(\"valid exists :\", os.path.exists(f\"{INPUT_DIR}/valid\"))\n",
        "print(\"invalid exists:\", os.path.exists(f\"{INPUT_DIR}/invalid\"))\n"
      ],
      "metadata": {
        "id": "Ld87INKgrtxa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29b04393-aa66-4772-b7da-fbb608b81f73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INPUT exists : True\n",
            "valid exists : False\n",
            "invalid exists: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def scan_exts(folder):\n",
        "    exts = []\n",
        "    for root, _, files in os.walk(folder):\n",
        "        for f in files:\n",
        "            exts.append(os.path.splitext(f)[1].lower())\n",
        "    return Counter(exts)\n",
        "\n",
        "print(\"Valid exts:\", scan_exts(f\"{INPUT_DIR}/Valid\"))\n",
        "print(\"Invalid exts:\", scan_exts(f\"{INPUT_DIR}/Invalid\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yUymwnFuC-t",
        "outputId": "34b812e4-1d18-41a3-a4f9-7ccb2e42532e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid exts: Counter({'.jpg': 299})\n",
            "Invalid exts: Counter({'.jpg': 300})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "random.seed(SEED)\n",
        "\n",
        "CLASS_MAP = {\n",
        "    \"valid\": \"Valid\",\n",
        "    \"invalid\": \"Invalid\"\n",
        "}\n",
        "\n",
        "def make_clean_dir(path):\n",
        "    path = Path(path)\n",
        "    if path.exists():\n",
        "        shutil.rmtree(path)\n",
        "    path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def list_all_images(folder):\n",
        "    exts = {\".jpg\",\".jpeg\",\".png\",\".webp\",\".bmp\",\".gif\",\".tif\",\".tiff\"}\n",
        "    return [p for p in Path(folder).rglob(\"*\") if p.is_file() and p.suffix.lower() in exts]\n",
        "\n",
        "def save_as_jpg(src, dst):\n",
        "    img = Image.open(src).convert(\"RGB\")\n",
        "    img.save(dst, format=\"JPEG\", quality=95)\n",
        "\n",
        "def split_convert_and_save(train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):\n",
        "    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-9\n",
        "\n",
        "    make_clean_dir(OUTPUT_DIR)\n",
        "    for sp in [\"train\",\"val\",\"test\"]:\n",
        "        for cls in [\"valid\",\"invalid\"]:\n",
        "            (Path(OUTPUT_DIR)/sp/cls).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    for cls, real_folder in CLASS_MAP.items():\n",
        "        src_cls = Path(INPUT_DIR) / real_folder\n",
        "        if not src_cls.exists():\n",
        "            raise FileNotFoundError(f\"Missing folder: {src_cls}\")\n",
        "\n",
        "        files = list_all_images(src_cls)\n",
        "        if len(files) == 0:\n",
        "            raise ValueError(f\"No images found in: {src_cls}\")\n",
        "\n",
        "        random.shuffle(files)\n",
        "        n = len(files)\n",
        "        n_train = int(n * train_ratio)\n",
        "        n_val   = int(n * val_ratio)\n",
        "\n",
        "        splits = {\n",
        "            \"train\": files[:n_train],\n",
        "            \"val\":   files[n_train:n_train+n_val],\n",
        "            \"test\":  files[n_train+n_val:]\n",
        "        }\n",
        "\n",
        "        for sp, flist in splits.items():\n",
        "            dst_dir = Path(OUTPUT_DIR) / sp / cls\n",
        "            for f in flist:\n",
        "                out = dst_dir / f\"{f.stem}.jpg\"\n",
        "                if out.exists():\n",
        "                    out = dst_dir / f\"{f.stem}_{random.randint(1000,9999)}.jpg\"\n",
        "                try:\n",
        "                    save_as_jpg(f, out)\n",
        "                except Exception as e:\n",
        "                    print(\"Skipping unreadable:\", f, \"|\", e)\n",
        "\n",
        "        print(f\" {cls.upper()} -> total:{n} train:{len(splits['train'])} val:{len(splits['val'])} test:{len(splits['test'])}\")\n",
        "\n",
        "split_convert_and_save()\n",
        "print(\" Output saved to:\", OUTPUT_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZ6aWTjbuU3c",
        "outputId": "b6768b57-ba72-4556-f27b-90f8f8a062aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " VALID -> total:299 train:209 val:44 test:46\n",
            " INVALID -> total:300 train:210 val:45 test:45\n",
            " Output saved to: /content/drive/MyDrive/DSGP_Group_32/NĀGA/Input Validation Model/Output\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_files(p):\n",
        "    c = 0\n",
        "    for _, _, files in os.walk(p):\n",
        "        c += len(files)\n",
        "    return c\n",
        "\n",
        "for sp in [\"train\",\"val\",\"test\"]:\n",
        "    for cls in [\"valid\",\"invalid\"]:\n",
        "        p = f\"{OUTPUT_DIR}/{sp}/{cls}\"\n",
        "        print(sp, cls, \"files =\", count_files(p))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4yJf3GPuhUu",
        "outputId": "ab2e827f-d86d-4673-eab9-ca7df4bc8c60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train valid files = 209\n",
            "train invalid files = 210\n",
            "val valid files = 44\n",
            "val invalid files = 45\n",
            "test valid files = 46\n",
            "test invalid files = 45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Load datasets"
      ],
      "metadata": {
        "id": "CmK4DAGA2Q7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    f\"{OUTPUT_DIR}/train\",\n",
        "    label_mode=\"binary\",\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH,\n",
        "    shuffle=True,\n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    f\"{OUTPUT_DIR}/val\",\n",
        "    label_mode=\"binary\",\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    f\"{OUTPUT_DIR}/test\",\n",
        "    label_mode=\"binary\",\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH,\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvtaqRK02SWl",
        "outputId": "64fabbc2-073a-4630-e69d-cab7c534a80f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 419 files belonging to 2 classes.\n",
            "Found 89 files belonging to 2 classes.\n",
            "Found 91 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Preprocess"
      ],
      "metadata": {
        "id": "R8Jk35AX19GH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_aug = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "    tf.keras.layers.RandomRotation(0.05),\n",
        "    tf.keras.layers.RandomZoom(0.1),\n",
        "])\n",
        "\n",
        "def prep_train(x,y):\n",
        "    x = tf.cast(x, tf.float32)/255.0\n",
        "    x = data_aug(x, training=True)\n",
        "    return x,y\n",
        "\n",
        "def prep_eval(x,y):\n",
        "    x = tf.cast(x, tf.float32)/255.0\n",
        "    return x,y\n",
        "\n",
        "train_ds = train_ds.map(prep_train, num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n",
        "val_ds   = val_ds.map(prep_eval,  num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n",
        "test_ds  = test_ds.map(prep_eval, num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "DuTgqt20196C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Train model"
      ],
      "metadata": {
        "id": "PaHyAouH25Hy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=(224,224,3),\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\"\n",
        ")\n",
        "base.trainable = False\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    base,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\", tf.keras.metrics.AUC(name=\"auc\")]\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(patience=4, restore_best_weights=True),\n",
        "    tf.keras.callbacks.ModelCheckpoint(\"best_validity_model.keras\", save_best_only=True)\n",
        "]\n",
        "\n",
        "model.fit(train_ds, validation_data=val_ds, epochs=15, callbacks=callbacks)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NW6XB3zo29PC",
        "outputId": "72f487b9-0c8a-4051-e4e6-b31c1c156bfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.5544 - auc: 0.5979 - loss: 0.7189 - val_accuracy: 0.6067 - val_auc: 0.7030 - val_loss: 0.6304\n",
            "Epoch 2/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 0.6632 - auc: 0.6939 - loss: 0.6400 - val_accuracy: 0.7191 - val_auc: 0.7854 - val_loss: 0.5659\n",
            "Epoch 3/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 0.7679 - auc: 0.8471 - loss: 0.4981 - val_accuracy: 0.7303 - val_auc: 0.7997 - val_loss: 0.5398\n",
            "Epoch 4/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.7336 - auc: 0.8182 - loss: 0.5259 - val_accuracy: 0.7303 - val_auc: 0.8111 - val_loss: 0.5273\n",
            "Epoch 5/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.8214 - auc: 0.8837 - loss: 0.4354 - val_accuracy: 0.7416 - val_auc: 0.8217 - val_loss: 0.5130\n",
            "Epoch 6/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.8285 - auc: 0.9056 - loss: 0.3972 - val_accuracy: 0.7416 - val_auc: 0.8313 - val_loss: 0.5013\n",
            "Epoch 7/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 0.8172 - auc: 0.8807 - loss: 0.4245 - val_accuracy: 0.7528 - val_auc: 0.8391 - val_loss: 0.4870\n",
            "Epoch 8/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.8152 - auc: 0.8989 - loss: 0.4077 - val_accuracy: 0.7528 - val_auc: 0.8444 - val_loss: 0.4808\n",
            "Epoch 9/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.8339 - auc: 0.9103 - loss: 0.3800 - val_accuracy: 0.7640 - val_auc: 0.8480 - val_loss: 0.4792\n",
            "Epoch 10/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1s/step - accuracy: 0.8470 - auc: 0.9141 - loss: 0.3762 - val_accuracy: 0.7753 - val_auc: 0.8540 - val_loss: 0.4706\n",
            "Epoch 11/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1s/step - accuracy: 0.8603 - auc: 0.9229 - loss: 0.3642 - val_accuracy: 0.7753 - val_auc: 0.8578 - val_loss: 0.4674\n",
            "Epoch 12/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.8354 - auc: 0.9273 - loss: 0.3600 - val_accuracy: 0.7865 - val_auc: 0.8626 - val_loss: 0.4576\n",
            "Epoch 13/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.8850 - auc: 0.9370 - loss: 0.3326 - val_accuracy: 0.7753 - val_auc: 0.8629 - val_loss: 0.4558\n",
            "Epoch 14/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 0.8554 - auc: 0.9220 - loss: 0.3562 - val_accuracy: 0.7865 - val_auc: 0.8747 - val_loss: 0.4465\n",
            "Epoch 15/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.8826 - auc: 0.9481 - loss: 0.3071 - val_accuracy: 0.7640 - val_auc: 0.8646 - val_loss: 0.4557\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a06cec30a70>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}