{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQHmQ5hEhpCYt1v5FJYG4Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zaviruuu/Naga--ML-Based-Snake-Identifier-for-Sri-Lanka-/blob/input_validation_model/Input_Validation_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Input Validation Model\n"
      ],
      "metadata": {
        "id": "6UYLjN85rhVo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Di6NJ0bZrcXM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "151fd69b-e409-4af8-8dd6-8e08c4829b99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "TensorFlow: 2.19.0\n"
          ]
        }
      ],
      "source": [
        "import os, shutil, random\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "print(\"TensorFlow:\", tf.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIR  = \"/content/drive/MyDrive/DSGP_Group_32/NĀGA/Input Validation Model/Dataset\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/DSGP_Group_32/NĀGA/Input Validation Model/Output\"\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH = 32\n",
        "SEED = 42\n",
        "\n",
        "print(\"INPUT exists :\", os.path.exists(INPUT_DIR))\n",
        "print(\"valid exists :\", os.path.exists(f\"{INPUT_DIR}/valid\"))\n",
        "print(\"invalid exists:\", os.path.exists(f\"{INPUT_DIR}/invalid\"))\n"
      ],
      "metadata": {
        "id": "Ld87INKgrtxa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "016efb44-964c-46c7-8a73-2770417bd802"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INPUT exists : True\n",
            "valid exists : False\n",
            "invalid exists: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def scan_exts(folder):\n",
        "    exts = []\n",
        "    for root, _, files in os.walk(folder):\n",
        "        for f in files:\n",
        "            exts.append(os.path.splitext(f)[1].lower())\n",
        "    return Counter(exts)\n",
        "\n",
        "print(\"Valid exts:\", scan_exts(f\"{INPUT_DIR}/Valid\"))\n",
        "print(\"Invalid exts:\", scan_exts(f\"{INPUT_DIR}/Invalid\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yUymwnFuC-t",
        "outputId": "12724457-0e6c-4f8e-e56b-50c3d990f299"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid exts: Counter({'.jpg': 517})\n",
            "Invalid exts: Counter({'.jpg': 494, '.png': 6})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "random.seed(SEED)\n",
        "\n",
        "CLASS_MAP = {\n",
        "    \"valid\": \"Valid\",\n",
        "    \"invalid\": \"Invalid\"\n",
        "}\n",
        "\n",
        "def make_clean_dir(path):\n",
        "    path = Path(path)\n",
        "    if path.exists():\n",
        "        shutil.rmtree(path)\n",
        "    path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def list_all_images(folder):\n",
        "    exts = {\".jpg\",\".jpeg\",\".png\",\".webp\",\".bmp\",\".gif\",\".tif\",\".tiff\"}\n",
        "    return [p for p in Path(folder).rglob(\"*\") if p.is_file() and p.suffix.lower() in exts]\n",
        "\n",
        "def save_as_jpg(src, dst):\n",
        "    img = Image.open(src).convert(\"RGB\")\n",
        "    img.save(dst, format=\"JPEG\", quality=95)\n",
        "\n",
        "def split_convert_and_save(train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):\n",
        "    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-9\n",
        "\n",
        "    make_clean_dir(OUTPUT_DIR)\n",
        "    for sp in [\"train\",\"val\",\"test\"]:\n",
        "        for cls in [\"valid\",\"invalid\"]:\n",
        "            (Path(OUTPUT_DIR)/sp/cls).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    for cls, real_folder in CLASS_MAP.items():\n",
        "        src_cls = Path(INPUT_DIR) / real_folder\n",
        "        if not src_cls.exists():\n",
        "            raise FileNotFoundError(f\"Missing folder: {src_cls}\")\n",
        "\n",
        "        files = list_all_images(src_cls)\n",
        "        if len(files) == 0:\n",
        "            raise ValueError(f\"No images found in: {src_cls}\")\n",
        "\n",
        "        random.shuffle(files)\n",
        "        n = len(files)\n",
        "        n_train = int(n * train_ratio)\n",
        "        n_val   = int(n * val_ratio)\n",
        "\n",
        "        splits = {\n",
        "            \"train\": files[:n_train],\n",
        "            \"val\":   files[n_train:n_train+n_val],\n",
        "            \"test\":  files[n_train+n_val:]\n",
        "        }\n",
        "\n",
        "        for sp, flist in splits.items():\n",
        "            dst_dir = Path(OUTPUT_DIR) / sp / cls\n",
        "            for f in flist:\n",
        "                out = dst_dir / f\"{f.stem}.jpg\"\n",
        "                if out.exists():\n",
        "                    out = dst_dir / f\"{f.stem}_{random.randint(1000,9999)}.jpg\"\n",
        "                try:\n",
        "                    save_as_jpg(f, out)\n",
        "                except Exception as e:\n",
        "                    print(\"Skipping unreadable:\", f, \"|\", e)\n",
        "\n",
        "        print(f\" {cls.upper()} -> total:{n} train:{len(splits['train'])} val:{len(splits['val'])} test:{len(splits['test'])}\")\n",
        "\n",
        "split_convert_and_save()\n",
        "print(\" Output saved to:\", OUTPUT_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZ6aWTjbuU3c",
        "outputId": "2a2b44f3-e50a-4082-b0b8-256800c9bc59"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " VALID -> total:517 train:361 val:77 test:79\n",
            " INVALID -> total:500 train:350 val:75 test:75\n",
            " Output saved to: /content/drive/MyDrive/DSGP_Group_32/NĀGA/Input Validation Model/Output\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_files(p):\n",
        "    c = 0\n",
        "    for _, _, files in os.walk(p):\n",
        "        c += len(files)\n",
        "    return c\n",
        "\n",
        "for sp in [\"train\",\"val\",\"test\"]:\n",
        "    for cls in [\"valid\",\"invalid\"]:\n",
        "        p = f\"{OUTPUT_DIR}/{sp}/{cls}\"\n",
        "        print(sp, cls, \"files =\", count_files(p))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4yJf3GPuhUu",
        "outputId": "49de28e6-4f2f-4aa6-cde2-810ed68160e6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train valid files = 361\n",
            "train invalid files = 350\n",
            "val valid files = 77\n",
            "val invalid files = 75\n",
            "test valid files = 79\n",
            "test invalid files = 75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Load datasets"
      ],
      "metadata": {
        "id": "CmK4DAGA2Q7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    f\"{OUTPUT_DIR}/train\",\n",
        "    label_mode=\"binary\",\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH,\n",
        "    shuffle=True,\n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    f\"{OUTPUT_DIR}/val\",\n",
        "    label_mode=\"binary\",\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    f\"{OUTPUT_DIR}/test\",\n",
        "    label_mode=\"binary\",\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH,\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvtaqRK02SWl",
        "outputId": "cab98427-1dae-4be0-b422-ffd921d7aec3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 711 files belonging to 2 classes.\n",
            "Found 152 files belonging to 2 classes.\n",
            "Found 154 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Preprocess"
      ],
      "metadata": {
        "id": "R8Jk35AX19GH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_aug = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "    tf.keras.layers.RandomRotation(0.05),\n",
        "    tf.keras.layers.RandomZoom(0.1),\n",
        "])\n",
        "\n",
        "def prep_train(x,y):\n",
        "    x = tf.cast(x, tf.float32)/255.0\n",
        "    x = data_aug(x, training=True)\n",
        "    return x,y\n",
        "\n",
        "def prep_eval(x,y):\n",
        "    x = tf.cast(x, tf.float32)/255.0\n",
        "    return x,y\n",
        "\n",
        "train_ds = train_ds.map(prep_train, num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n",
        "val_ds   = val_ds.map(prep_eval,  num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n",
        "test_ds  = test_ds.map(prep_eval, num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "DuTgqt20196C"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Train model"
      ],
      "metadata": {
        "id": "PaHyAouH25Hy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=(224,224,3),\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\"\n",
        ")\n",
        "base.trainable = False\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    base,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\", tf.keras.metrics.AUC(name=\"auc\")]\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(patience=4, restore_best_weights=True),\n",
        "    tf.keras.callbacks.ModelCheckpoint(\"best_validity_model.keras\", save_best_only=True)\n",
        "]\n",
        "\n",
        "model.fit(train_ds, validation_data=val_ds, epochs=15, callbacks=callbacks)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NW6XB3zo29PC",
        "outputId": "f5a33fe1-127f-40a6-dd67-6bd0a7cca119"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Epoch 1/15\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.5757 - auc: 0.5910 - loss: 0.7198 - val_accuracy: 0.7500 - val_auc: 0.7791 - val_loss: 0.5648\n",
            "Epoch 2/15\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 2s/step - accuracy: 0.7025 - auc: 0.7705 - loss: 0.5749 - val_accuracy: 0.7697 - val_auc: 0.8267 - val_loss: 0.5115\n",
            "Epoch 3/15\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - accuracy: 0.7381 - auc: 0.8285 - loss: 0.5137 - val_accuracy: 0.7763 - val_auc: 0.8492 - val_loss: 0.4784\n",
            "Epoch 4/15\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.7698 - auc: 0.8465 - loss: 0.4807 - val_accuracy: 0.7895 - val_auc: 0.8672 - val_loss: 0.4494\n",
            "Epoch 5/15\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - accuracy: 0.8018 - auc: 0.8913 - loss: 0.4156 - val_accuracy: 0.8289 - val_auc: 0.8820 - val_loss: 0.4268\n",
            "Epoch 6/15\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - accuracy: 0.8114 - auc: 0.8818 - loss: 0.4282 - val_accuracy: 0.8289 - val_auc: 0.8898 - val_loss: 0.4189\n",
            "Epoch 7/15\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 2s/step - accuracy: 0.8013 - auc: 0.8960 - loss: 0.4137 - val_accuracy: 0.8289 - val_auc: 0.8931 - val_loss: 0.4037\n",
            "Epoch 8/15\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2s/step - accuracy: 0.8116 - auc: 0.9037 - loss: 0.3996 - val_accuracy: 0.8224 - val_auc: 0.9001 - val_loss: 0.3983\n",
            "Epoch 9/15\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 2s/step - accuracy: 0.8162 - auc: 0.9105 - loss: 0.3824 - val_accuracy: 0.8289 - val_auc: 0.9007 - val_loss: 0.3921\n",
            "Epoch 10/15\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 2s/step - accuracy: 0.8266 - auc: 0.9173 - loss: 0.3677 - val_accuracy: 0.8355 - val_auc: 0.9037 - val_loss: 0.3891\n",
            "Epoch 11/15\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2s/step - accuracy: 0.8452 - auc: 0.9198 - loss: 0.3600 - val_accuracy: 0.8289 - val_auc: 0.9029 - val_loss: 0.3848\n",
            "Epoch 12/15\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 2s/step - accuracy: 0.8287 - auc: 0.9275 - loss: 0.3444 - val_accuracy: 0.8224 - val_auc: 0.9080 - val_loss: 0.3835\n",
            "Epoch 13/15\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 2s/step - accuracy: 0.8490 - auc: 0.9179 - loss: 0.3572 - val_accuracy: 0.8289 - val_auc: 0.9087 - val_loss: 0.3792\n",
            "Epoch 14/15\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 2s/step - accuracy: 0.8648 - auc: 0.9496 - loss: 0.3044 - val_accuracy: 0.8421 - val_auc: 0.9087 - val_loss: 0.3735\n",
            "Epoch 15/15\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - accuracy: 0.8576 - auc: 0.9365 - loss: 0.3264 - val_accuracy: 0.8289 - val_auc: 0.9047 - val_loss: 0.3887\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f20241ebda0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc, test_auc = model.evaluate(test_ds)\n",
        "print(\"Test Acc:\", test_acc, \"| Test AUC:\", test_auc)\n",
        "\n",
        "SAVE_PATH = \"/content/drive/MyDrive/DSGP_Group_32/NĀGA/Input Validation Model/valid_invalid_model.keras\"\n",
        "model.save(SAVE_PATH)\n",
        "print(\" Saved:\", SAVE_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjBX5W0LL5Q3",
        "outputId": "df087936-9be6-4d91-fee5-dd6d756455cc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.7823 - auc: 0.6091 - loss: 0.4370\n",
            "Test Acc: 0.8311688303947449 | Test AUC: 0.9054852724075317\n",
            " Saved: /content/drive/MyDrive/DSGP_Group_32/NĀGA/Input Validation Model/valid_invalid_model.keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 1) Get prediction probabilities\n",
        "probs = model.predict(test_ds).ravel()\n",
        "\n",
        "# 2) Convert probabilities to class labels (0/1)\n",
        "preds = (probs >= 0.5).astype(int)\n",
        "\n",
        "# 3) Get true labels from test dataset\n",
        "y_true = np.concatenate(\n",
        "    [y.numpy().astype(int).ravel() for _, y in test_ds],\n",
        "    axis=0\n",
        ")\n",
        "\n",
        "print(\"y_true length:\", len(y_true))\n",
        "print(\"preds length :\", len(preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdzzkhISMufE",
        "outputId": "9779a14d-24f2-44c2-c09f-29c69f752722"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step\n",
            "y_true length: 154\n",
            "preds length : 154\n"
          ]
        }
      ]
    }
  ]
}