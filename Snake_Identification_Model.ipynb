{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPoYghpfJc1pyoCDhKx6M02",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zaviruuu/Naga--ML-Based-Snake-Identifier-for-Sri-Lanka-/blob/snake_identification_model/Snake_Identification_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##NĀGA - SNAKE IDENTIFICATION MODEL"
      ],
      "metadata": {
        "id": "XxalvW8fSlJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "s63ZYvPJPSk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SRC_DIR = \"/content/drive/MyDrive/DSGP_Group_32/NĀGA/Snake Identification Model/Dataset\"\n",
        "OUT_DIR = \"/content/drive/MyDrive/DSGP_Group_32/NĀGA/Snake Identification Model/Output\""
      ],
      "metadata": {
        "id": "xFJPNp9SPTnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split ratios (simple + standard)\n",
        "TRAIN_RATIO = 0.70\n",
        "VAL_RATIO   = 0.15\n",
        "TEST_RATIO  = 0.15\n",
        "\n",
        "#Image settings\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 15\n",
        "SEED = 42"
      ],
      "metadata": {
        "id": "TarlAaDvYoRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##EDA\n",
        "#Class distribution\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "DATA_DIR = \"/content/drive/MyDrive/DSGP_Group_32/NĀGA/Snake Identification Model/Dataset\"\n",
        "\n",
        "classes = sorted([d.name for d in Path(DATA_DIR).iterdir() if d.is_dir()])\n",
        "counts = []\n",
        "for c in classes:\n",
        "    counts.append(len([p for p in Path(DATA_DIR, c).glob(\"*\") if p.suffix.lower() in [\".jpg\",\".jpeg\",\".png\"]]))\n",
        "\n",
        "plt.figure()\n",
        "plt.bar(classes, counts)\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.title(\"Class Distribution (Images per Class)\")\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eLPGebGXdAmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sample images\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "def show_samples(data_dir, classes, n_per_class=3):\n",
        "    plt.figure(figsize=(n_per_class*3, len(classes)*3))\n",
        "    k = 1\n",
        "    for c in classes:\n",
        "        imgs = [p for p in Path(data_dir, c).glob(\"*\") if p.suffix.lower() in [\".jpg\",\".jpeg\",\".png\"]]\n",
        "        pick = random.sample(imgs, min(n_per_class, len(imgs)))\n",
        "        for p in pick:\n",
        "            img = Image.open(p).convert(\"RGB\")\n",
        "            plt.subplot(len(classes), n_per_class, k)\n",
        "            plt.imshow(img)\n",
        "            plt.axis(\"off\")\n",
        "            plt.title(c)\n",
        "            k += 1\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "show_samples(DATA_DIR, classes, n_per_class=3)"
      ],
      "metadata": {
        "id": "BdpES_5JlRh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Brightness distribution\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "all_imgs = []\n",
        "for c in classes:\n",
        "    all_imgs += [p for p in Path(DATA_DIR, c).glob(\"*\") if p.suffix.lower() in [\".jpg\",\".jpeg\",\".png\"]]\n",
        "\n",
        "sample = random.sample(all_imgs, min(400, len(all_imgs)))\n",
        "\n",
        "brightness = []\n",
        "for p in sample:\n",
        "    img = Image.open(p).convert(\"L\")\n",
        "    brightness.append(np.array(img).mean())\n",
        "\n",
        "plt.figure()\n",
        "plt.hist(brightness, bins=30)\n",
        "plt.title(\"Brightness Distribution (Sample)\")\n",
        "plt.xlabel(\"Mean brightness (0–255)\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sNMlutDqmIek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Split train/val/test\n",
        "import random, shutil, os\n",
        "from pathlib import Path\n",
        "\n",
        "random.seed(SEED)\n",
        "\n",
        "#Detect classes (folder names)\n",
        "classes = [d.name for d in Path(SRC_DIR).iterdir() if d.is_dir()]\n",
        "print(\"Classes found:\", classes)\n",
        "\n",
        "#Create output folder structure\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    for c in classes:\n",
        "        Path(f\"{OUT_DIR}/{split}/{c}\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "IMG_EXTS = {\".jpg\"}\n",
        "\n",
        "#Copy files into splits\n",
        "for c in classes:\n",
        "    files = [f for f in Path(f\"{SRC_DIR}/{c}\").glob(\"*\") if f.suffix.lower() in IMG_EXTS]\n",
        "    random.shuffle(files)\n",
        "\n",
        "    n = len(files)\n",
        "    n_train = int(n * TRAIN_RATIO)\n",
        "    n_val   = int(n * VAL_RATIO)\n",
        "\n",
        "    train_files = files[:n_train]\n",
        "    val_files   = files[n_train:n_train + n_val]\n",
        "    test_files  = files[n_train + n_val:]\n",
        "\n",
        "    for f in train_files:\n",
        "        shutil.copy2(f, f\"{OUT_DIR}/train/{c}/{f.name}\")\n",
        "    for f in val_files:\n",
        "        shutil.copy2(f, f\"{OUT_DIR}/val/{c}/{f.name}\")\n",
        "    for f in test_files:\n",
        "        shutil.copy2(f, f\"{OUT_DIR}/test/{c}/{f.name}\")\n",
        "\n",
        "    print(f\"{c}: total={n} | train={len(train_files)} | val={len(val_files)} | test={len(test_files)}\")\n",
        "\n",
        "print(\"\\nSplit complete ->\", OUT_DIR)"
      ],
      "metadata": {
        "id": "BkR_jz_E5T6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load data(with simple preprocessing)\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "#Train: rescale + augmentation\n",
        "train_gen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "#Val/Test: onlyrescale(no augmentation)\n",
        "val_gen = ImageDataGenerator(rescale=1./255)\n",
        "test_gen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "EBs89zTn9vkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_gen.flow_from_directory(\n",
        "    f\"{OUT_DIR}/train\",\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\",\n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "val_data = val_gen.flow_from_directory(\n",
        "    f\"{OUT_DIR}/val\",\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\",\n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "test_data = test_gen.flow_from_directory(\n",
        "    f\"{OUT_DIR}/test\",\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "print(\"\\nDataset summary\")\n",
        "print(f\"Train set      : {train_data.samples} images | {train_data.num_classes} classes\")\n",
        "print(f\"Validation set : {val_data.samples} images | {val_data.num_classes} classes\")\n",
        "print(f\"Test set       : {test_data.samples} images | {test_data.num_classes} classes\")\n",
        "\n",
        "print(\"\\nLabel mapping (class indices):\", train_data.class_indices)"
      ],
      "metadata": {
        "id": "i7lrGu0q-1af"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Class weights(helps imbalance)\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "y_train = train_data.classes\n",
        "weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_train), y=y_train)\n",
        "class_weight = {i: w for i, w in enumerate(weights)}\n",
        "print(\"Class weights:\", class_weight)"
      ],
      "metadata": {
        "id": "afv4Q51P_5Ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Build model(MobileNetV2 Transfer Learning)\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "num_classes = train_data.num_classes\n",
        "\n",
        "base_model = MobileNetV2(\n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\"\n",
        ")\n",
        "base_model.trainable = False\n",
        "\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(num_classes, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "O-txYdB1V4ii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Train\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    validation_data=val_data,\n",
        "    epochs=EPOCHS,\n",
        "    class_weight=class_weight\n",
        ")"
      ],
      "metadata": {
        "id": "k_xi3Mq1kIrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate on test set\n",
        "test_loss, test_acc = model.evaluate(test_data)\n",
        "print(f\"\\nTesting Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "id": "MD34YvOFhAgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Confusion matrix\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "pred_probs = model.predict(test_data)\n",
        "y_pred = np.argmax(pred_probs, axis=1)\n",
        "y_true = test_data.classes\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(\"\\nConfusion Matrix:\\n\", cm)"
      ],
      "metadata": {
        "id": "9zzYwKwdSKYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Confusion matrix (counts)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(cm)\n",
        "plt.title(\"Confusion Matrix (Counts)\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.xticks(ticks=np.arange(len(labels_sorted)), labels=labels_sorted, rotation=45, ha=\"right\")\n",
        "plt.yticks(ticks=np.arange(len(labels_sorted)), labels=labels_sorted)\n",
        "\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "labels_sorted = [None] * len(test_data.class_indices)\n",
        "for name, idx in test_data.class_indices.items():\n",
        "    labels_sorted[idx] = name"
      ],
      "metadata": {
        "id": "d5JBzzg-SLI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Confusion matrix (normalized)\n",
        "cm_norm = cm.astype(\"float\") / cm.sum(axis=1, keepdims=True)\n",
        "cm_norm = np.nan_to_num(cm_norm)  # avoid NaN if a row is empty\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(cm_norm, vmin=0, vmax=1)\n",
        "plt.title(\"Confusion Matrix (Normalized)\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.xticks(ticks=np.arange(len(labels_sorted)), labels=labels_sorted, rotation=45, ha=\"right\")\n",
        "plt.yticks(ticks=np.arange(len(labels_sorted)), labels=labels_sorted)\n",
        "\n",
        "for i in range(cm_norm.shape[0]):\n",
        "    for j in range(cm_norm.shape[1]):\n",
        "        plt.text(j, i, f\"{cm_norm[i, j]*100:.0f}%\", ha=\"center\", va=\"center\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gjiVYGN1SVJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Accuracy/Lose curves\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Accuracy curve\n",
        "plt.figure()\n",
        "plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
        "plt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
        "plt.title(\"Training vs Validation Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#Loss curve\n",
        "plt.figure()\n",
        "plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
        "plt.title(\"Training vs Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dsP3yVT2hEvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Classification report\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(y_true, y_pred, target_names=labels_sorted))"
      ],
      "metadata": {
        "id": "1uzZVq2ayTNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Per-class F1 score\n",
        "report = classification_report(y_true, y_pred, target_names=labels_sorted, output_dict=True)\n",
        "f1_scores = [report[c][\"f1-score\"] for c in labels_sorted]\n",
        "\n",
        "plt.figure()\n",
        "plt.bar(labels_sorted, f1_scores)\n",
        "plt.title(\"Per-Class F1 Score\")\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"F1\")\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.ylim(0, 1)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "f0KEuphmyTy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ROC-AUC curves\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "K = len(labels_sorted)\n",
        "\n",
        "y_true_bin = label_binarize(y_true, classes=list(range(K)))\n",
        "\n",
        "plt.figure()\n",
        "for i in range(K):\n",
        "    fpr, tpr, _ = roc_curve(y_true_bin[:, i], pred_probs[:, i])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, label=f\"{labels_sorted[i]} (AUC={roc_auc:.2f})\")\n",
        "\n",
        "plt.title(\"ROC Curves (One-vs-Rest)\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.legend(fontsize=8)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "la-fjHPhyYOM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}